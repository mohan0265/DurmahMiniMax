Final README.md (Replace existing if needed)
# ğŸ§ ğŸ—£ï¸ Durmah Voice Loop â€“ ChatGPT Voice Mode Clone

A production-grade, real-time voice loop widget inspired by OpenAI ChatGPT Voice Mode. Built with OpenAI, ElevenLabs, Supabase, and deployed using Render + Netlify.

---

## ğŸš€ Features

- ğŸ™ï¸ One-click **Voice Mode Activation**
- ğŸ”„ Real-time streaming with OpenAI + ElevenLabs
- ğŸ” Google OAuth-only authentication (no email/password login)
- ğŸ§  Memory & integrity layer (optional JWT, Supabase RLS)
- ğŸ“± Fully responsive (mobile-ready)
- ğŸ› ï¸ Production-ready: `Dockerfile`, `render.yaml`, `netlify.toml`, `.env`

---

## ğŸ§° Tech Stack

| Layer       | Tech                     |
|-------------|--------------------------|
| Frontend    | React + Tailwind         |
| Voice AI    | OpenAI Whisper + ElevenLabs |
| Backend     | Node.js (Express)        |
| Auth & DB   | Supabase                 |
| Hosting     | Render (server) + Netlify (client) |

---

## ğŸ” Authentication

**Google OAuth Only**: This application uses Google OAuth exclusively for authentication. No email/password login is supported.

- Users must sign in with their Google account
- Durham University email addresses (@durham.ac.uk) automatically receive voice access
- Clean, secure authentication flow with no password management required

---

## ğŸ”§ Environment Variables

Create `.env.local` in `/Server` based on `.env.example`.

| Variable                    | Purpose                          |
|----------------------------|----------------------------------|
| `OPENAI_API_KEY`           | For transcription (Whisper)      |
| `ELEVENLABS_API_KEY`       | For TTS voice output             |
| `SUPABASE_URL`             | Supabase project URL             |
| `SUPABASE_SERVICE_ROLE_KEY`| For server-side Supabase access  |
| `ALLOWED_ORIGINS`          | CORS policy                      |
| `JWT_SECRET`               | Enable JWT-auth (optional)       |
| `PORT`                     | Server port (default: `3001`)    |
| `DEBUG_VOICE`              | Set `true` to see logs           |

---

## ğŸ”¨ Local Dev Instructions

```bash
# Install dependencies
npm install --prefix Client
npm install --prefix Server

# Start development server
npm run dev --prefix Client
npm run dev --prefix Server

ğŸ§ª Live Deployment Setup

Server: Deployed on Render
 using render.yaml

Client: Deployed on Netlify
 using netlify.toml

Add your environment variables under Render/Netlify project settings

ğŸ“‚ Folder Structure
DurmahMiniMax/
â”œâ”€â”€ Client/              # React Frontend
â”‚   â”œâ”€â”€ src/             # Voice hook, context, UI
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ Server/              # Node.js backend
â”‚   â”œâ”€â”€ routes/          # Realtime, voice API
â”‚   â”œâ”€â”€ services/        # Integrity, memory, socket
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ .env.example
â”œâ”€â”€ render.yaml
â”œâ”€â”€ netlify.toml
â””â”€â”€ README.md

ğŸ“˜ Related Docs

voice-loop-README.md
 â€“ Technical implementation notes

voice-loop-ClaudePrompt.md
 â€“ Prompt used to build this voice loop

INTEGRATION_SUMMARY.md
 â€“ Notes for integration into MyDurhamLaw

DEPLOYMENT.md
 â€“ Hosting setup instructions

ğŸ§  Future Roadmap

 Claude/GPT auto mode switching (text vs voice)

 Continuous voice conversations (multi-turn UX)

 Browser tab wake/sleep awareness

 Emotion detection & Wellbeing tracking (from original Durmah project)

ğŸ«¡ Credits

Built by mohan0265

In collaboration with Claude and ChatGPT