# ğŸ§  VOICE LOOP FILES â€“ Real-Time AI Assistant System

This folder contains the **core voice interaction loop** for a ChatGPT-style AI assistant. Once deployed with correct environment variables, it enables:

ğŸ¤ Mic Input â†’ OpenAI Whisper/Chat â†’ ğŸ—£ï¸ TTS Response â†’ Audio Playback

---

## âœ… FILE STRUCTURE

```
Client/
â””â”€â”€ src/
    â”œâ”€â”€ components/
    â”‚   â””â”€â”€ DurmahWidget.tsx       â† UI toggle for voice mode
    â””â”€â”€ hooks/
        â”œâ”€â”€ useRealtimeWebRTC.js   â† Mic capture + WebRTC + TTS playback
        â””â”€â”€ useChat.js             â† Optional: state handling, transcript
Server/
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ realtime.js                â† POST /api/realtime/session (OpenAI key)
â”‚   â””â”€â”€ voice.js                   â† Optional routing for voice control
â””â”€â”€ services/
    â”œâ”€â”€ realtime-voice.js          â† OpenAI & ElevenLabs voice logic
    â””â”€â”€ socket.js                  â† (Optional) transcript events
```

---

## ğŸŒ DEPLOYMENT REQUIREMENTS

| Env Variable               | Purpose                         |
|---------------------------|---------------------------------|
| `OPENAI_API_KEY`          | Used for Whisper + Chat + TTS   |
| `ELEVENLABS_API_KEY`      | (Optional) For TTS synthesis    |
| `VITE_SESSION_ENDPOINT`   | Frontend URL to `realtime.js`   |
| `VITE_ALLOW_ANON_VOICE`   | Set to `true` to allow testing  |
| `VITE_REQUIRE_LOGIN`      | Set to `false` if no auth yet   |

---

## ğŸš€ TO RUN LOCALLY

**Client**
```bash
cd Client
npm install
npm run dev
```

**Server**
```bash
cd Server
npm install
node index.js
```

Then open `http://localhost:5173`

---

## ğŸ§ª TEST WITH CLAUDE CODE

You can ask Claude:
- â€œWhat does `useRealtimeWebRTC.js` do?â€
- â€œCan you improve `DurmahWidget.tsx` to support live transcript preview?â€
- â€œWhere should I insert speaker audio playback?â€
- â€œMake this as fast and natural as ChatGPT Voice.â€

